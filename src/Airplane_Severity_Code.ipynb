{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hot_encoding_features(X):\n",
    "        one_hot_encoding = pd.get_dummies(X[['Accident_Type_Code','Violations']])\n",
    "        \n",
    "        return one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(df):\n",
    "#     df['Accident_Type_Code'] = pd.Categorical(df['Accident_Type_Code'])\n",
    "#     df['Violations'] = pd.Categorical(df['Violations'])\n",
    "# #     df['Days_Since_Inspection'] = pd.Categorical(df['Days_Since_Inspection'])\n",
    "# #     df['Total_Safety_Complaints'] = pd.Categorical(df['Total_Safety_Complaints'])\n",
    "#     one_hot_encoding = compute_hot_encoding_features(df)\n",
    "#     df = pd.concat([df, one_hot_encoding], axis=1)\n",
    "    df = df.drop(['Accident_Type_Code','Violations'],axis=1, inplace=False)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standization(df):\n",
    "    scaler_X = preprocessing.StandardScaler().fit(df[['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric']])\n",
    "    scaled_data = scaler_X.transform(df[['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric']])\n",
    "    scaled_data_df = pd.DataFrame(data = scaled_data,  columns = ['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric'])\n",
    "    df[['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric']] = scaled_data_df[['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric']]\n",
    "         \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(df):\n",
    "    scaler_X = preprocessing.MinMaxScaler().fit(df[['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric']])\n",
    "    scaled_data = scaler_X.transform(df[['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric']])\n",
    "    scaled_data_df = pd.DataFrame(data = scaled_data,  columns = ['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric'])\n",
    "    df[['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric']] = scaled_data_df[['Safety_Score','Days_Since_Inspection','Total_Safety_Complaints','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Violations','Adverse_Weather_Metric']]\n",
    "         \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    'Minor_Damage_And_Injuries': 0,\n",
    "    'Significant_Damage_And_Fatalities': 1,\n",
    "    'Significant_Damage_And_Serious_Injuries': 2,\n",
    "    'Highly_Fatal_And_Damaging': 3\n",
    "}\n",
    "inverse_class_map = {\n",
    "    0: 'Minor_Damage_And_Injuries',\n",
    "    1: 'Significant_Damage_And_Fatalities',\n",
    "    2: 'Significant_Damage_And_Serious_Injuries',\n",
    "    3: 'Highly_Fatal_And_Damaging'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reading():\n",
    "    data = pd.read_csv(\"../data/data_folder/train.csv\")\n",
    "    \n",
    "    X = data.drop(['Severity', 'Accident_ID'],axis=1, inplace=False)\n",
    "    Y = data['Severity']\n",
    "    Y = Y.map(class_map).astype(np.uint8)\n",
    "    \n",
    "    X = data_preparation(X)\n",
    "#     X = Standization(X)\n",
    "#     X = Normalization(X)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_xgboost(dtrain):\n",
    "    \n",
    "    \n",
    "    param = {\n",
    "        'max_depth': 5,  # the maximum depth of each tree\n",
    "#         'booster':'dart',\n",
    "        #'gamma': 3,\n",
    "        #'min_child_weight': 1,\n",
    "        #'subsample': 1,\n",
    "        #'colsample_bytree': 1,\n",
    "        #'alpha': 0.1,\n",
    "        'eta': 0.1,  # the training step for each iteration\n",
    "        'silent': 1,  # logging mode - quiet\n",
    "        'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "        'num_class': 4    # the number of classes that exist in this datset\n",
    "    }  \n",
    "    nrounds = 1000  # the number of training iterations\n",
    "    \n",
    "    \n",
    "    bst_xgb = xgb.train(param, dtrain,nrounds)\n",
    "    \n",
    "    return bst_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf(X_train, y_train):\n",
    "    \n",
    "    clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=100, max_features=5, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=3,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "    \n",
    "    bst_rf = clf.fit(X_train, y_train)\n",
    "    \n",
    "    return bst_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_svm(X_train, y_train):\n",
    "    clf = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, \n",
    "              probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False,\n",
    "              max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "    \n",
    "    bst_svc = clf.fit(X_train, y_train)\n",
    "    \n",
    "    return bst_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n",
      "       'Control_Metric', 'Turbulence_In_gforces', 'Cabin_Temperature',\n",
      "       'Max_Elevation', 'Adverse_Weather_Metric'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uia89739/miniconda3/envs/py3.7/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "X,Y = data_reading()\n",
    "print(X.columns)    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify=Y, test_size=0.1)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "xgb_model = model_xgboost(dtrain)            #XGBoost model training\n",
    "rf_model =  model_rf(X_train, y_train)       #RF model training\n",
    "svm_model =  model_svm(X_train, y_train)     #SVM model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_F1_score_XGB: 1.0 /n\n",
      "CV_F1_score_XGB: 0.9489774040171063\n"
     ]
    }
   ],
   "source": [
    "train_preds = xgb_model.predict(dtrain)\n",
    "train_preds = np.asarray([np.argmax(line) for line in train_preds])\n",
    "train_score = f1_score(y_train, train_preds, average='weighted')\n",
    "print('train_F1_score_XGB:', train_score ,'/n')\n",
    "\n",
    "cv_preds = xgb_model.predict(dtest)\n",
    "cv_preds_xgboost = np.asarray([np.argmax(line) for line in cv_preds])\n",
    "score_xgb = f1_score(y_test, cv_preds_xgboost, average='weighted')\n",
    "print('CV_F1_score_XGB:', score_xgb )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_F1_score_RF: 1.0 /n\n",
      "CV_F1_score_RF: 0.8941295600644422 /n\n"
     ]
    }
   ],
   "source": [
    "train_y_pred_rf = rf_model.predict(X_train)\n",
    "train_score_rf = f1_score(y_train, train_y_pred_rf, average='weighted')\n",
    "print('train_F1_score_RF:', train_score_rf ,'/n')\n",
    "\n",
    "cv_y_pred_rf = rf_model.predict(X_test)\n",
    "score_rf = f1_score(y_test, cv_y_pred_rf, average='weighted')\n",
    "print('CV_F1_score_RF:', score_rf ,'/n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uia89739/miniconda3/envs/py3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_F1_score_RF: 0.1424753254617015 /n\n",
      "CV_F1_score_RF: 0.14256704980842913 /n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uia89739/miniconda3/envs/py3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_y_pred_svm = svm_model.predict(X_train)\n",
    "train_score_svm = f1_score(y_train, train_y_pred_svm, average='weighted')\n",
    "print('train_F1_score_RF:', train_score_svm ,'/n')\n",
    "\n",
    "cv_y_pred_svm = svm_model.predict(X_test)\n",
    "score_svm = f1_score(y_test, cv_y_pred_svm, average='weighted')\n",
    "print('CV_F1_score_RF:', score_svm ,'/n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_pred = ((cv_y_pred_rf*0.5)+(cv_preds_xgboost*0.5)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9641363776844659\n"
     ]
    }
   ],
   "source": [
    "ensamble_score = f1_score(y_test, ensamble_pred, average='weighted')\n",
    "print(ensamble_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set(test_data):\n",
    "    test_data_set = test_data.drop(['Accident_ID'],axis=1, inplace=False)\n",
    "    \n",
    "    test_data_set = data_preparation(test_data_set)\n",
    "#     test_data_set = Standization(test_data_set)\n",
    "#     test_data_set = Normalization(test_data_set)\n",
    "    \n",
    "    dtest_1 = xgb.DMatrix(test_data_set)\n",
    "    \n",
    "    prob_xgb = xgb_model.predict(dtest_1)\n",
    "    pred_xgb = np.asarray([np.argmax(line) for line in prob_xgb])     #prediction of XGBoost\n",
    "    \n",
    "    pred_rf = rf_model.predict(test_data_set)                             #pediction of RF\n",
    "    \n",
    "    pred_svm = svm_model.predict(test_data_set)                             #pediction of SVM\n",
    "    \n",
    "    ensamble_pred_test = ((pred_rf*0.4)+(pred_xgb*0.6))             #prediction of ensamble\n",
    "    \n",
    "    return pred_xgb, pred_rf, pred_svm, ensamble_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data/data_folder/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_xgb, final_pred_rf, pred_svm, final_pred_ensamble = test_set(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose prediction of your choice for sbmission \n",
    "\n",
    "submission = pd.DataFrame([test_data['Accident_ID'], np.vectorize(inverse_class_map.get)(final_pred_xgb)], index=['Accident_ID', 'Severity']).T\n",
    "submission.to_csv( \"../data/data_folder/submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
